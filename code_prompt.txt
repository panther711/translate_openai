目标：
1. 定义现在的 Model Class 为基类，构造函数参数不变，timeout 默认值设置为600。新增一个接口 make_request，由子类实现；
2. 定义两个继承自 Model Class 的子类 GLMModel 和 OpenAIModel；
3. 将 translate_pdf 方法从构造 prompt 到调用 _translate 方法整合，作为GLMModel 类的 make_request 方法；

    def translate_pdf(self, pdf_file_path: str, file_format: str = 'PDF', target_language: str = '中文', output_file_path: str = None, pages: Optional[int] = None):
        self.book = self.pdf_parser.parse_pdf(pdf_file_path, pages)

        for page_idx, page in enumerate(self.book.pages):
            for content_idx, content in enumerate(page.contents):
                prompt = self.prompt_maker.translate_prompt(content, target_language)
                LOG.info(f"[prompt]{prompt}")
                payload = {
                    "prompt": prompt,
                    "history": []
                }
                translation, status = self._translate(payload)
                LOG.info(f"[translation]{translation}")
                
                # Update the content in self.book.pages directly
                self.book.pages[page_idx].contents[content_idx].set_translation(translation, status)

        self.writer.save_translated_book(self.book, output_file_path, file_format)


    def _translate(self, payload):
        try:
            response = requests.post(self.model.model_url, json=payload, timeout=self.model.timeout)
            response.raise_for_status()
            response_dict = response.json()
            translation = response_dict["response"]
            return translation, True
        except requests.exceptions.RequestException as e:
            raise Exception(f"请求异常：{e}")
        except requests.exceptions.Timeout as e:
            raise Exception(f"请求超时：{e}")
        except simplejson.errors.JSONDecodeError as e:
            raise Exception("Error: response is not valid JSON format.")
        except Exception as e:
            raise Exception(f"发生了未知错误：{e}")
        return "", False

4. OpenAIModel 类的 make_request 方法与GLMModel 类的目标一致，构造 requests 参考以下代码示例：

Example：
    import os
    import openai
    openai.api_key = os.getenv("OPENAI_API_KEY")
    openai.Completion.create(
    model="text-davinci-003",
    prompt="Say this is a test",
    max_tokens=7,
    temperature=0
    )

Response：
    {
    "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
    "object": "text_completion",
    "created": 1589478378,
    "model": "text-davinci-003",
    "choices": [
        {
        "text": "\n\nThis is indeed a test",
        "index": 0,
        "logprobs": null,
        "finish_reason": "length"
        }
    ],
    "usage": {
        "prompt_tokens": 5,
        "completion_tokens": 7,
        "total_tokens": 12
    }
    }

