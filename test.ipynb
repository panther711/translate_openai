{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96b11f6e-dea0-47b7-aa24-0bab12e9ab76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "class ConfigLoader:\n",
    "    def __init__(self, config_path):\n",
    "        self.config_path = config_path\n",
    "\n",
    "    def load_config(self):\n",
    "        with open(self.config_path, \"r\") as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        return config\n",
    "\n",
    "import argparse\n",
    "\n",
    "class ArgumentParser:\n",
    "    def __init__(self):\n",
    "        self.parser = argparse.ArgumentParser(description='Translate English PDF book to Chinese.')\n",
    "        self.parser.add_argument('--config', type=str, default='config.yaml', help='Configuration file with model and API settings.')\n",
    "        self.parser.add_argument('--book', type=str, help='PDF file to translate.')\n",
    "        self.parser.add_argument('--model_url', type=str, help='The URL of the translation model API.')\n",
    "        self.parser.add_argument('--timeout', type=int, help='Timeout for the API request in seconds.')\n",
    "\n",
    "    def parse_arguments(self):\n",
    "        args = self.parser.parse_args()\n",
    "        return args\n",
    "\n",
    "class Environment:\n",
    "    @staticmethod\n",
    "    def is_jupyter():\n",
    "        try:\n",
    "            get_ipython()\n",
    "            return True\n",
    "        except NameError:\n",
    "            return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28d67e4e-aa44-4f5f-a47c-46fe92b0303e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from enum import Enum, auto\n",
    "\n",
    "class ModelType(Enum):\n",
    "    ChatGLM = auto()\n",
    "    GPT_3 = auto()\n",
    "    GPT_3_5 = auto()\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, model_url, timeout, model_type=ModelType.ChatGLM):\n",
    "        self.model_url = model_url\n",
    "        self.timeout = timeout\n",
    "        self.model_type = model_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dafdc59-8552-4f59-9468-a51fc22dd8dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TranslatorException:\n",
    "    def __init__(self, e):\n",
    "        self.exception = e\n",
    "\n",
    "    def handle_exception(self):\n",
    "        if isinstance(self.exception, requests.exceptions.RequestException):\n",
    "            return f\"请求异常：{self.exception}\"\n",
    "        elif isinstance(self.exception, requests.exceptions.Timeout):\n",
    "            return f\"请求超时：{self.exception}\"\n",
    "        elif isinstance(self.exception, simplejson.errors.JSONDecodeError):\n",
    "            return \"Error: response is not valid JSON format.\"\n",
    "        else:\n",
    "            return f\"发生了未知错误：{self.exception}\"\n",
    "        \n",
    "        \n",
    "class PageOutOfRangeException(Exception):\n",
    "    def __init__(self, book_pages, requested_pages):\n",
    "        self.book_pages = book_pages\n",
    "        self.requested_pages = requested_pages\n",
    "        super().__init__(f\"Page out of range: Book has {book_pages} pages, but {requested_pages} pages were requested.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b867ac30-74c3-4683-8123-c6c1300d21b4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from enum import Enum, auto\n",
    "\n",
    "class ContentType(Enum):\n",
    "    TEXT = auto()\n",
    "    TABLE = auto()\n",
    "    IMAGE = auto()\n",
    "\n",
    "@dataclass\n",
    "class Content:\n",
    "    content_type: ContentType\n",
    "    original: any\n",
    "    translation: any = None\n",
    "\n",
    "    def set_translation(s\n",
    "                        elf, translation):\n",
    "        self.translation = translation\n",
    "\n",
    "class Page:\n",
    "    def __init__(self):\n",
    "        self.contents = []\n",
    "\n",
    "    def add_content(self, content: Content):\n",
    "        self.contents.append(content)\n",
    "\n",
    "class Book:\n",
    "    def __init__(self):\n",
    "        self.pages = []\n",
    "\n",
    "    def add_page(self, page: Page):\n",
    "        self.pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f33721d4-31ca-4b64-b510-62e9705964c8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "\n",
    "class PDFTranslator:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.book = Book()\n",
    "        self.translated_book = Book()\n",
    "        self.translate_status = []\n",
    "        self.success_rate = 0\n",
    "        self.headers = {\n",
    "            'Content-Type': 'application/json;charset=utf-8'\n",
    "        }\n",
    "\n",
    "    def parse_pdf(self, book, pages=None):\n",
    "        self.book = Book()\n",
    "        with pdfplumber.open(book) as pdf:\n",
    "            if pages is not None:\n",
    "                page_numbers = range(min(pages, len(pdf.pages)))\n",
    "            else:\n",
    "                page_numbers = range(len(pdf.pages))\n",
    "\n",
    "            for i in page_numbers:\n",
    "                page = pdf.pages[i]\n",
    "                page_contents = Page()\n",
    "\n",
    "                # 提取文本\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    paragraphs = text.split(\"\\n\")\n",
    "                    for paragraph in paragraphs:\n",
    "                        page_contents.add_text(paragraph)\n",
    "\n",
    "                # 提取表格\n",
    "                tables = page.extract_tables()\n",
    "                if tables:\n",
    "                    for table in tables:\n",
    "                        page_contents.add_table(table)\n",
    "\n",
    "                # 提取图片\n",
    "                images = page.images\n",
    "                if images:\n",
    "                    for img_obj in images:\n",
    "                        img = Image.open(img_obj)\n",
    "                        page_contents.add_image(img)\n",
    "\n",
    "                self.book.add_page(page_contents)\n",
    "\n",
    "    # def handle_translation_response(self, response):\n",
    "    #     try:\n",
    "    #         response.raise_for_status()\n",
    "    #         response_dict = response.json()\n",
    "    #         translation = response_dict[\"response\"]\n",
    "    #         self.translated_book.append(translation)\n",
    "    #         self.translate_status.append(1)\n",
    "    #     except Exception as e:\n",
    "    #         exception_handler = TranslatorException(e)\n",
    "    #         error_message = exception_handler.handle_exception()\n",
    "    #         print(error_message, file=sys.stderr)\n",
    "    #         self.translated_book.append(\"[翻译失败]\")\n",
    "    #         self.translate_status.append(0)\n",
    "\n",
    "    def handle_translation_response(self, response, content):\n",
    "        try:\n",
    "            response.raise_for_status()\n",
    "            response_dict = response.json()\n",
    "            translation = response_dict[\"response\"]\n",
    "            content.translation = translation\n",
    "            self.translate_status.append(1)\n",
    "        except Exception as e:\n",
    "            exception_handler = TranslatorException(e)\n",
    "            error_message = exception_handler.handle_exception()\n",
    "            print(error_message, file=sys.stderr)\n",
    "            content.translation = \"[翻译失败]\"\n",
    "            self.translate_status.append(0)\n",
    "            \n",
    "\n",
    "    def translate_contents(self, book):\n",
    "        successful_requests = 0\n",
    "        total_requests = len(self.book)\n",
    "\n",
    "        with open(f\"{book[:-4]}_analyzed.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            for i, text in enumerate(self.book):\n",
    "                prompt = f\"翻译为中文：{text}\"\n",
    "                data = {\n",
    "                    \"prompt\": prompt,\n",
    "                    \"history\": []\n",
    "                }\n",
    "                response = requests.post(self.model.model_url, json=data, timeout=self.model.timeout)\n",
    "                self.handle_translation_response(response)\n",
    "                f.write(self.translated_book[-1])\n",
    "\n",
    "    def calculate_success_rate(self):\n",
    "        successful_requests = sum(self.translate_status)\n",
    "        total_requests = len(self.translate_status)\n",
    "        self.success_rate = successful_requests / total_requests * 100\n",
    "    \n",
    "    def translate_pdf(self, book, pages=None):\n",
    "        self.parse_pdf(book, pages)\n",
    "        self.translate_contents(book)\n",
    "        self.calculate_success_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "065a9090-b22b-434c-8289-078fd9cbb4e9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29524/2404162948.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# 实例化 PDFTranslator 类，并调用 translate_pdf() 方法\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtranslator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDFTranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"翻译完成！\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_29524/1741643848.py\u001b[0m in \u001b[0;36mtranslate_pdf\u001b[0;34m(self, book, pages)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranslate_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate_contents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_success_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_29524/1741643848.py\u001b[0m in \u001b[0;36mparse_pdf\u001b[0;34m(self, book, pages)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mimg_obj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                         \u001b[0mpage_contents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "# 使用示例\n",
    "environment = Environment()\n",
    "\n",
    "args = None\n",
    "if not environment.is_jupyter():\n",
    "    argument_parser = ArgumentParser()\n",
    "    args = argument_parser.parse_arguments()\n",
    "    config_loader = ConfigLoader(args.config)\n",
    "else:\n",
    "    config_loader = ConfigLoader('config.yaml')\n",
    "\n",
    "config = config_loader.load_config()\n",
    "book = args.book if hasattr(args, 'book') and args.book else config['book']\n",
    "model_url = args.model_url if hasattr(args, 'model_url') and args.model_url else config['model_url']\n",
    "timeout = args.timeout if hasattr(args, 'timeout') and args.timeout else config['timeout']\n",
    "\n",
    "model = Model(model_url=model_url, timeout=timeout)\n",
    "\n",
    "# 实例化 PDFTranslator 类，并调用 translate_pdf() 方法\n",
    "translator = PDFTranslator(model)\n",
    "translator.translate_pdf(book, pages=5)\n",
    "\n",
    "print(\"翻译完成！\")\n",
    "print(\"翻译成功率：\", round(translator.success_rate, 4))\n",
    "print(\"翻译状态：\", translator.translate_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fa759a7-6ce8-41d9-a020-22d92e3b0fe6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LanguageModelsareUnsupervisedMultitaskLearners\\nlappingtrainingdatawithtestevaluationtasks.\\nParameters Layers d\\nmodel\\n2.2.InputRepresentation 117M 12 768\\n345M 24 1024\\nAgenerallanguagemodel(LM)shouldbeabletocompute\\n762M 36 1280\\ntheprobabilityof(andalsogenerate)anystring. Current 1542M 48 1600\\nlargescaleLMsincludepre-processingstepssuchaslower-\\ncasing,tokenization,andout-of-vocabularytokenswhich Table2.Architecturehyperparametersforthe4modelsizes.\\nrestrictthespaceofmodel-ablestrings. Whileprocessing\\nUnicodestringsasasequenceofUTF-8byteselegantlyful-\\nfillsthisrequirementasexemplifiedinworksuchasGillick few modifications. Layer normalization (Ba et al., 2016)\\net al. (2015), current byte-level LMs are not competitive was moved to the input of each sub-block, similar to a\\nwith word-level LMs on large scale datasets such as the pre-activation residual network (He et al., 2016) and an\\nOneBillionWordBenchmark(Al-Rfouetal.,2018). We additionallayernormalizationwasaddedafterthefinalself-\\nobservedasimilarperformancegapinourownattemptsto attentionblock. Amodifiedinitializationwhichaccounts\\ntrainstandardbyte-levelLMsonWebText. fortheaccumulationontheresidualpathwithmodeldepth\\nisused. Wescaletheweightsofresiduallayersatinitial-\\nByte Pair Encoding (BPE) (Sennrich et al., 2015) is a √\\nization by a factor of 1/ N where N is the number of\\npracticalmiddlegroundbetweencharacterandwordlevel\\nresiduallayers. Thevocabularyisexpandedto50,257. We\\nlanguagemodelingwhicheffectivelyinterpolatesbetween\\nalsoincreasethecontextsizefrom512to1024tokensand\\nwordlevelinputsforfrequentsymbolsequencesandchar-\\nalargerbatchsizeof512isused.\\nacterlevelinputsforinfrequentsymbolsequences. Despite\\nitsname,referenceBPEimplementationsoftenoperateon\\nUnicodecodepointsandnotbytesequences. Theseimple- 3.Experiments\\nmentationswouldrequireincludingthefullspaceofUni-\\nWetrainedandbenchmarkedfourLMswithapproximately\\ncodesymbolsinordertomodelallUnicodestrings. This\\nlog-uniformlyspacedsizes. Thearchitecturesaresumma-\\nwouldresultinabasevocabularyofover130,000before\\nrized in Table 2. The smallest model is equivalent to the\\nanymulti-symboltokensareadded. Thisisprohibitively\\noriginal GPT, and the second smallest equivalent to the\\nlargecomparedtothe32,000to64,000tokenvocabularies\\nlargestmodelfromBERT(Devlinetal.,2018). Ourlargest\\noften used with BPE. In contrast, a byte-level version of\\nmodel,whichwecallGPT-2,hasoveranorderofmagni-\\nBPEonlyrequiresabasevocabularyofsize256. However,\\ntudemoreparametersthanGPT.Thelearningrateofeach\\ndirectlyapplyingBPEtothebytesequenceresultsinsub-\\nmodelwasmanuallytunedforthebestperplexityona5%\\noptimalmergesduetoBPEusingagreedyfrequencybased\\nheld-outsampleofWebText. AllmodelsstillunderfitWeb-\\nheuristicforbuildingthetokenvocabulary. Weobserved\\nTextandheld-outperplexityhasasofyetimprovedgiven\\nBPEincludingmanyversionsofcommonwordslikedog\\nmoretrainingtime.\\nsince they occur in many variations such as dog. dog!\\ndog? . Thisresultsinasub-optimalallocationoflimited\\n3.1.LanguageModeling\\nvocabularyslotsandmodelcapacity. Toavoidthis,wepre-\\nventBPEfrommergingacrosscharactercategoriesforany As an initial step towards zero-shot task transfer, we are\\nbytesequence. Weaddanexceptionforspaceswhichsig- interested in understanding how WebText LM’s perform\\nnificantlyimprovesthecompressionefficiencywhileadding atzero-shotdomaintransferontheprimarytasktheyare\\nonlyminimalfragmentationofwordsacrossmultiplevocab trainedfor–languagemodeling. Sinceourmodeloperates\\ntokens. onabytelevelanddoesnotrequirelossypre-processing\\nortokenization,wecanevaluateitonanylanguagemodel\\nThisinputrepresentationallowsustocombinetheempirical\\nbenchmark. Results on language modeling datasets are\\nbenefitsofword-levelLMswiththegeneralityofbyte-level\\ncommonlyreportedinaquantitywhichisascaledorex-\\napproaches. Sinceourapproachcanassignaprobabilityto\\nponentiatedversionoftheaveragenegativelogprobability\\nanyUnicodestring,thisallowsustoevaluateourLMson\\npercanonicalpredictionunit-usuallyacharacter,abyte,or\\nany dataset regardless of pre-processing, tokenization, or\\naword. Weevaluatethesamequantitybycomputingthe\\nvocabsize.\\nlog-probabilityofadatasetaccordingtoaWebTextLMand\\ndividingbythenumberofcanonicalunits.Formanyofthese\\n2.3.Model\\ndatasets,WebTextLMswouldbetestedsignificantlyout-\\nWeuseaTransformer(Vaswanietal.,2017)basedarchi- of-distribution,havingtopredictaggressivelystandardized\\ntectureforourLMs. Themodellargelyfollowsthedetails text,tokenizationartifactssuchasdisconnectedpunctuation\\nof the OpenAI GPT model (Radford et al., 2018) with a and contractions, shuffled sentences, and even the string'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator.book_contents[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05af8495-c31d-4e7f-95d8-19d34ea20881",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (2568351515.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_29524/2568351515.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    a = \"0 发布日期和时间  0:00 实际  预测  前一次\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb549f-142c-4471-906a-8c34b656cc43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
